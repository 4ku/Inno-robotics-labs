{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gau9xEXMGY8s"
      },
      "source": [
        "# Neural Machine Translation with Transformer Using PyTorch\n",
        "In this notebook we are going to perform machine translation using Transformer. \n",
        "\n",
        "Specifically, we are going to train a sequence to sequence model for French-to-English translation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z579-ISl9Zj6"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU7hop0m8MNi",
        "outputId": "c1133747-f0e9-4062-c1bf-def9b7992c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastBPE\n",
            "  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacremoses) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sacremoses) (4.65.0)\n",
            "Building wheels for collected packages: fastBPE, sacremoses\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp39-cp39-linux_x86_64.whl size=762563 sha256=f33fc86d86d91d146ae92809af45ae57e6ac6ecdcf1edf4e013b6dbb60d8b599\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/10/20/0691b69b472ff8530a7e608674d5bd1cbc772f4d6071c8accf\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=6b2506a96d5991e1bbbc5562c19dcc64b93f6c3759b39186fab5b98fd5f88868\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built fastBPE sacremoses\n",
            "Installing collected packages: fastBPE, sacremoses\n",
            "Successfully installed fastBPE-0.1.0 sacremoses-0.0.53\n"
          ]
        }
      ],
      "source": [
        "!pip install fastBPE sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qT20LFmb3jSW"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "import fastBPE\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from sacremoses import MosesDetokenizer, MosesTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import IterableDataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh0N1AxpXhGY",
        "outputId": "2d6c9c20-f036-4896-bba7-cc590a12a3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Bhpi9gD_3UHZRFmcn7Czkb73jHN8CUAL\n",
            "To: /content/Dataset-fr-eng.txt\n",
            "\r  0% 0.00/28.7M [00:00<?, ?B/s]\r100% 28.7M/28.7M [00:00<00:00, 286MB/s]\r100% 28.7M/28.7M [00:00<00:00, 285MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1Bhpi9gD_3UHZRFmcn7Czkb73jHN8CUAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JD8Qy0eC0ZtA"
      },
      "outputs": [],
      "source": [
        "f = open('Dataset-fr-eng.txt', encoding='UTF-8').read().strip().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0mVlB0W14b4G"
      },
      "outputs": [],
      "source": [
        "lines = f\n",
        "# sample size (smaller sample size to reduce computation)\n",
        "num_examples = 30000 \n",
        "# creates lists containing each pair\n",
        "original_word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]\n",
        "data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"fr\",\"whatever\"])\n",
        "data = data[['eng','fr']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "913VSLih4lY3",
        "outputId": "bdd8eb81-54ef-4ee3-cd1a-4e5bc52e2cf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    eng                              fr\n",
              "0   Go.                            Va !\n",
              "1   Go.                         Marche.\n",
              "2   Go.                         Bouge !\n",
              "3   Hi.                         Salut !\n",
              "4   Hi.                          Salut.\n",
              "5  Run!                         Cours !\n",
              "6  Run!                        Courez !\n",
              "7  Run!  Prenez vos jambes à vos cous !\n",
              "8  Run!                          File !\n",
              "9  Run!                         Filez !"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eef95732-8e0f-40b0-a86b-304a3ec7b4fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Marche.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Bouge !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Prenez vos jambes à vos cous !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Run!</td>\n",
              "      <td>File !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Filez !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eef95732-8e0f-40b0-a86b-304a3ec7b4fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eef95732-8e0f-40b0-a86b-304a3ec7b4fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eef95732-8e0f-40b0-a86b-304a3ec7b4fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ0nnMJs8epQ",
        "outputId": "e2830342-f7ee-4419-8382-cec3c542fd43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vXaIlIRnx7rm98K9zTNEsrJodNvUg4F-\n",
            "To: /content/tokenizer.zip\n",
            "\r  0% 0.00/619k [00:00<?, ?B/s]\r100% 619k/619k [00:00<00:00, 168MB/s]\n",
            "Archive:  tokenizer.zip\n",
            "  inflating: bpecodes                \n",
            "  inflating: dict.en.txt             \n",
            "  inflating: dict.fr.txt             \n"
          ]
        }
      ],
      "source": [
        "!gdown 1vXaIlIRnx7rm98K9zTNEsrJodNvUg4F-\n",
        "!unzip tokenizer.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bs3h59CGoHgo"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, bpe_file: str, vocab_file: str):        \n",
        "        self.bpe = fastBPE.fastBPE(bpe_file)\n",
        "        self.tokenizer = MosesTokenizer('fr')\n",
        "        self.detokenizer = MosesDetokenizer('en')\n",
        "        \n",
        "        tmp = open(vocab_file, encoding='utf-8').read().split('\\n')\n",
        "        tmp = [x.split()[0] for x in tmp[:-1]]\n",
        "        self.vocab = ['<sos>', '<pad>', '<eos>', '<unk>'] + tmp\n",
        "        self.t2i = {t : i for i, t in enumerate(self.vocab)}\n",
        "    \n",
        "    def encode(self, sent: str, add_eos = False):\n",
        "        sent = self.tokenizer.tokenize(sent, aggressive_dash_splits=True, return_str=True)\n",
        "        tokens = self.bpe.apply([sent])[0].split()\n",
        "        tokens = [self.t2i[t] if t in self.t2i else self.t2i['<unk>'] for t in tokens]\n",
        "        if add_eos:\n",
        "            tokens += [self.t2i['<eos>']]\n",
        "        return tokens\n",
        "    \n",
        "    def decode(self, tokens: list):\n",
        "        sent = [self.vocab[t] for t in tokens]\n",
        "        sent = ' '.join(sent)\n",
        "        sent = (sent + ' ').replace('@@ ', '').rstrip()\n",
        "        sent = self.detokenizer.detokenize(sent.split())\n",
        "        return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HI8AYfZ1oHgo"
      },
      "outputs": [],
      "source": [
        "class NMT_dataset(IterableDataset):\n",
        "    def __init__(self, data):\n",
        "        self.fr_data = data[\"fr\"]\n",
        "        self.en_data = data[\"eng\"]\n",
        "        self.src_tokenizer = Tokenizer(*SRC_VOCAB_FILE)\n",
        "        self.trg_tokenizer = Tokenizer(*TRG_VOCAB_FILE)\n",
        "    \n",
        "    def src_line_mapper(self, line):\n",
        "        line = line.replace('\\n', '')\n",
        "        tokens = self.src_tokenizer.encode(line, True)\n",
        "        return tokens\n",
        "    \n",
        "    def trg_line_mapper(self, line):\n",
        "        line = line.replace('\\n', '')\n",
        "        tokens = self.trg_tokenizer.encode(line, True)\n",
        "        return tokens\n",
        "    \n",
        "    def __iter__(self):\n",
        "        mapped_fr_iter = map(self.src_line_mapper, self.fr_data)\n",
        "        mapped_en_iter = map(self.trg_line_mapper, self.en_data)\n",
        "        \n",
        "        fr_en_iter = zip(mapped_fr_iter, mapped_en_iter)\n",
        "        return fr_en_iter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jrMi1TUVoHgo"
      },
      "outputs": [],
      "source": [
        "def pad_batch(batch):\n",
        "    max_src_len = max(len(x) for x, _ in batch)\n",
        "    max_trg_len = max(len(y) for _, y in batch)\n",
        "    max_src_len = min(max_src_len, MAX_SEQ_LEN)\n",
        "    max_trg_len = min(max_trg_len, MAX_SEQ_LEN)\n",
        "    \n",
        "    src_batch = [x[:max_src_len] for x, _ in batch]\n",
        "    trg_batch = [y[:max_trg_len] for _, y in batch]\n",
        "    \n",
        "    src_batch = [np.pad(x, (0, max_src_len - len(x)), constant_values=PAD_ID) for x in src_batch]\n",
        "    trg_batch = [np.pad(y, (0, max_trg_len - len(y)), constant_values=PAD_ID) for y in trg_batch]\n",
        "    return torch.tensor(src_batch, dtype=torch.long), torch.tensor(trg_batch, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf3unAOsoHgl",
        "outputId": "041d894e-8c91-44fc-b8c3-8481ed4907f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "SRC_VOCAB_FILE = [f'bpecodes', f'dict.fr.txt']\n",
        "TRG_VOCAB_FILE = [f'bpecodes', f'dict.en.txt']\n",
        "\n",
        "MAX_SEQ_LEN = 127\n",
        "PAD_ID = 1\n",
        "BOUND_ID = 2\n",
        "\n",
        "# model params\n",
        "enc_ffn_dims = 1024\n",
        "dec_ffn_dims = 512\n",
        "d_model = 256\n",
        "heads = 8\n",
        "N = 3\n",
        "WARM_UP_STEPS = 4000\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 300\n",
        "NUM_BATCHES = len(data) // BATCH_SIZE + (1 if len(data) % BATCH_SIZE > 0 else 0)\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "umNX5bWUoHgo"
      },
      "outputs": [],
      "source": [
        "dataset = NMT_dataset(data)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=pad_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZqWUSePRoHgp"
      },
      "outputs": [],
      "source": [
        "src_vocab_size = len(dataset.src_tokenizer.vocab)\n",
        "trg_vocab_size = len(dataset.trg_tokenizer.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uJ4M0BYzoHgm"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_len=256):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        half_dim = d_model // 2\n",
        "        pe = torch.tensor(10000) / (torch.arange(1, half_dim + 1, dtype=torch.float) * 2 - 1)\n",
        "        pe = torch.exp(torch.arange(0, half_dim, dtype=torch.float) * -pe.log())\n",
        "        pe = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1) * pe.unsqueeze(0)\n",
        "        pe = torch.cat([torch.sin(pe), torch.cos(pe)], dim=1).view(max_seq_len, -1)\n",
        "        \n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        length = x.size(1) + 2\n",
        "        return x + self.pe[:, 2:length]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MXpYECDXoHgm"
      },
      "outputs": [],
      "source": [
        "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        mask = mask.unsqueeze(1)\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    scores = F.softmax(scores, dim=-1)\n",
        "    \n",
        "    if dropout is not None:\n",
        "        scores = dropout(scores)\n",
        "        \n",
        "    output = torch.matmul(scores, v)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qwn9OUZ4oHgm"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, heads, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_model // heads\n",
        "        self.h = heads\n",
        "        \n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "    \n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        bs = q.size(0)\n",
        "                \n",
        "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
        "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
        "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
        "        \n",
        "        k = k.transpose(1,2)\n",
        "        q = q.transpose(1,2)\n",
        "        v = v.transpose(1,2)\n",
        "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
        "        \n",
        "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
        "        output = self.out(concat)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "54oZIEqYoHgm"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__() \n",
        "        self.dropout = dropout\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.dropout(F.relu(self.linear_1(x)), p=self.dropout, training=self.training)\n",
        "        x = self.linear_2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pzRHNAShoHgn"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, ffn_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model, ffn_dim)\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        "        x = x + F.dropout(self.attn(x, x, x, mask), p=self.dropout, training=self.training)\n",
        "        x = self.norm_1(x)\n",
        "        x = x + F.dropout(self.ff(x), p=self.dropout, training=self.training)\n",
        "        x = self.norm_2(x)\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, ffn_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "        self.norm_3 = nn.LayerNorm(d_model)\n",
        "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
        "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model, ffn_dim)\n",
        "        \n",
        "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
        "        x = x + F.dropout(self.attn_1(x, x, x, trg_mask), p=self.dropout, training=self.training)\n",
        "        x = self.norm_1(x)\n",
        "        x = x + F.dropout(self.attn_2(x, e_outputs, e_outputs, src_mask), p=self.dropout, training=self.training)\n",
        "        x = self.norm_2(x)\n",
        "        x = x + F.dropout(self.ff(x), p=self.dropout, training=self.training)\n",
        "        x = self.norm_3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MnztUmEGoHgn"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads, ffn_dim):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.d_model = d_model\n",
        "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, heads, ffn_dim) for _ in range(N)])\n",
        "\n",
        "    def forward(self, src, mask):\n",
        "        x = self.embed(src) * np.sqrt(self.d_model)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, mask)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads, ffn_dim):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.d_model = d_model\n",
        "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, heads, ffn_dim) for _ in range(N)])\n",
        "\n",
        "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
        "        x = self.embed(trg) * np.sqrt(self.d_model)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wAz5M91ioHgn"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, trg_vocab_size, d_model, N, heads, enc_ffn_dim, dec_ffn_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, N, heads, enc_ffn_dim)\n",
        "        self.decoder = Decoder(trg_vocab_size, d_model, N, heads, dec_ffn_dim)\n",
        "\n",
        "    def forward(self, src, trg, src_mask, trg_mask):\n",
        "        e_outputs = self.encoder(src, src_mask)\n",
        "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
        "        output = F.linear(d_output, self.decoder.embed.weight)\n",
        "        return output\n",
        "    \n",
        "    def out(self, trg, e_outputs, src_mask, trg_mask):\n",
        "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
        "        output = F.linear(d_output, self.decoder.embed.weight)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7VCuEmToHgp"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wuzomZ0NoHgp"
      },
      "outputs": [],
      "source": [
        "model = Transformer(src_vocab_size, trg_vocab_size, d_model, N, heads, enc_ffn_dims, dec_ffn_dims).to(DEVICE)\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dZtoWFP-oHgo"
      },
      "outputs": [],
      "source": [
        "def nopeak_mask(size):\n",
        "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
        "    np_mask = torch.from_numpy(np_mask) == 0\n",
        "    return np_mask.to(DEVICE)\n",
        "\n",
        "\n",
        "def create_masks(src, trg):\n",
        "    src_mask = (src != PAD_ID).unsqueeze(-2)\n",
        "\n",
        "    if trg is not None:\n",
        "        trg_mask = (trg != PAD_ID).unsqueeze(-2)\n",
        "        size = trg.size(1)\n",
        "        np_mask = nopeak_mask(size).to(DEVICE)\n",
        "        trg_mask = trg_mask & np_mask\n",
        "    else:\n",
        "        trg_mask = None\n",
        "        \n",
        "    return src_mask, trg_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "b47BXmCKoHgq"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "\n",
        "class Scheduler(_LRScheduler):\n",
        "    def __init__(self, optimizer, dim_embed, warmup_steps, last_epoch=-1):\n",
        "        self.dim_embed = dim_embed\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.num_param_groups = len(optimizer.param_groups)\n",
        "\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "        \n",
        "    def get_lr(self):\n",
        "        lr = calc_lr(self._step_count, self.dim_embed, self.warmup_steps)\n",
        "        return [lr] * self.num_param_groups\n",
        "\n",
        "\n",
        "def calc_lr(step, dim_embed, warmup_steps):\n",
        "    return dim_embed**(-0.5) * min(step**(-0.5), step * warmup_steps**(-1.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "U6Bvvox4oHgq"
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler = Scheduler(optim, d_model, WARM_UP_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oT8nBviIoHgq"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(epochs):\n",
        "    model.train()\n",
        "    \n",
        "    start = time.time()\n",
        "    temp = start\n",
        "    total_loss = 0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for i, (src, trg) in enumerate(tqdm(dataloader, total=NUM_BATCHES)):\n",
        "\n",
        "            src = src.to(DEVICE)\n",
        "            trg = trg.to(DEVICE)\n",
        "            \n",
        "            trg_input = F.pad(trg[:, :-1], (1, 0), value=BOUND_ID)\n",
        "            src_mask, trg_mask = create_masks(src, trg_input)\n",
        "            preds = model(src, trg_input, src_mask, trg_mask)\n",
        "            \n",
        "            optim.zero_grad()\n",
        "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), trg.view(-1), ignore_index=PAD_ID)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            \n",
        "            total_loss += loss\n",
        "            \n",
        "        loss_avg = total_loss / NUM_BATCHES\n",
        "        print(f\"{epoch} iter = {i + 1}, loss = {loss_avg}, lr = {scheduler.get_lr()[0]}\")\n",
        "        total_loss = 0\n",
        "        tokens = np.argmax(F.softmax(preds, -1).data.tolist(), 2)\n",
        "        print(f'Prediction: {dataset.trg_tokenizer.decode(tokens[0])}')\n",
        "        print(f'True: {dataset.trg_tokenizer.decode(trg[0].data.tolist())}')\n",
        "\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtdBa7DQoHgq",
        "outputId": "fd903939-fae2-43c6-935f-85c295c176ea",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]<ipython-input-10-7394687f6a77>:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  return torch.tensor(src_batch, dtype=torch.long), torch.tensor(trg_batch, dtype=torch.long)\n",
            "100%|██████████| 100/100 [00:22<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 iter = 100, loss = 10.648383140563965, lr = 2.4705294220065465e-07\n",
            "Prediction: BraBraBrasoftware BraBraBraBulletin Bra\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 iter = 100, loss = 10.613430976867676, lr = 4.941058844013093e-07\n",
            "Prediction: BraBraBraCM BraBrapétroinstructions Bra\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 iter = 100, loss = 10.559117317199707, lr = 7.41158826601964e-07\n",
            "Prediction: <eos> papers BraBra204 <eos> <eos> sentencing.\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 iter = 100, loss = 10.490191459655762, lr = 9.882117688026186e-07\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 iter = 100, loss = 10.41409969329834, lr = 1.2352647110032732e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 iter = 100, loss = 10.339945793151855, lr = 1.482317653203928e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:20<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 iter = 100, loss = 10.269495964050293, lr = 1.7293705954045826e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 iter = 100, loss = 10.197644233703613, lr = 1.976423537605237e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 iter = 100, loss = 10.12109088897705, lr = 2.223476479805892e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 iter = 100, loss = 10.036911010742188, lr = 2.4705294220065464e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 iter = 100, loss = 9.94424057006836, lr = 2.717582364207201e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 iter = 100, loss = 9.842901229858398, lr = 2.964635306407856e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 iter = 100, loss = 9.732585906982422, lr = 3.2116882486085104e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 iter = 100, loss = 9.61385440826416, lr = 3.4587411908091652e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 iter = 100, loss = 9.486661911010742, lr = 3.7057941330098196e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 iter = 100, loss = 9.351572036743164, lr = 3.952847075210474e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 iter = 100, loss = 9.208643913269043, lr = 4.199900017411129e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 iter = 100, loss = 9.058470726013184, lr = 4.446952959611784e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 iter = 100, loss = 8.90114688873291, lr = 4.694005901812438e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 iter = 100, loss = 8.737567901611328, lr = 4.941058844013093e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 iter = 100, loss = 8.568110466003418, lr = 5.188111786213748e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21 iter = 100, loss = 8.39338207244873, lr = 5.435164728414402e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 iter = 100, loss = 8.214130401611328, lr = 5.682217670615057e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23 iter = 100, loss = 8.030685424804688, lr = 5.929270612815712e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24 iter = 100, loss = 7.844273567199707, lr = 6.176323555016366e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 iter = 100, loss = 7.655529499053955, lr = 6.423376497217021e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26 iter = 100, loss = 7.465632915496826, lr = 6.670429439417676e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27 iter = 100, loss = 7.2753214836120605, lr = 6.9174823816183304e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28 iter = 100, loss = 7.085670471191406, lr = 7.164535323818985e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29 iter = 100, loss = 6.898202419281006, lr = 7.411588266019639e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 iter = 100, loss = 6.713583946228027, lr = 7.658641208220294e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31 iter = 100, loss = 6.533064842224121, lr = 7.905694150420949e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32 iter = 100, loss = 6.3578033447265625, lr = 8.152747092621604e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33 iter = 100, loss = 6.1885504722595215, lr = 8.399800034822258e-06\n",
            "Prediction: <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34 iter = 100, loss = 6.026398181915283, lr = 8.646852977022913e-06\n",
            "Prediction: <eos> <eos> <eos> <eos>. <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35 iter = 100, loss = 5.873161315917969, lr = 8.893905919223568e-06\n",
            "Prediction: <eos> <eos> <eos>.. <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 iter = 100, loss = 5.731993198394775, lr = 9.140958861424223e-06\n",
            "Prediction: <eos> <eos> <eos>.. <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37 iter = 100, loss = 5.604893207550049, lr = 9.388011803624876e-06\n",
            "Prediction: <eos> <eos> <eos>.. <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38 iter = 100, loss = 5.492290019989014, lr = 9.63506474582553e-06\n",
            "Prediction: <eos> <eos>... <eos> <eos> <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39 iter = 100, loss = 5.394021511077881, lr = 9.882117688026186e-06\n",
            "Prediction: <eos> <eos>..... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40 iter = 100, loss = 5.306873798370361, lr = 1.012917063022684e-05\n",
            "Prediction: <eos> <eos>..... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41 iter = 100, loss = 5.227205753326416, lr = 1.0376223572427495e-05\n",
            "Prediction: <eos> <eos>..... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 iter = 100, loss = 5.151206970214844, lr = 1.062327651462815e-05\n",
            "Prediction: <eos> <eos>..... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43 iter = 100, loss = 5.077214241027832, lr = 1.0870329456828805e-05\n",
            "Prediction: <eos> <eos>..... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 iter = 100, loss = 5.004464149475098, lr = 1.111738239902946e-05\n",
            "Prediction: <eos> <eos>..... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 iter = 100, loss = 4.933346271514893, lr = 1.1364435341230114e-05\n",
            "Prediction: <eos>...... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 iter = 100, loss = 4.86358118057251, lr = 1.161148828343077e-05\n",
            "Prediction: <eos> <eos> <eos>.... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47 iter = 100, loss = 4.796123504638672, lr = 1.1858541225631424e-05\n",
            "Prediction: <eos> <eos> <eos>.... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 iter = 100, loss = 4.730810642242432, lr = 1.2105594167832077e-05\n",
            "Prediction: <eos> <eos> <eos>.... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 iter = 100, loss = 4.667760372161865, lr = 1.2352647110032732e-05\n",
            "Prediction: <eos> <eos> <eos>.. <eos>. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 iter = 100, loss = 4.605944633483887, lr = 1.2599700052233387e-05\n",
            "Prediction: <eos> <eos>..... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 iter = 100, loss = 4.546443462371826, lr = 1.2846752994434042e-05\n",
            "Prediction: <eos> <eos> <eos>.... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 iter = 100, loss = 4.490264415740967, lr = 1.3093805936634696e-05\n",
            "Prediction: <eos> <eos> <eos>.... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53 iter = 100, loss = 4.4340620040893555, lr = 1.3340858878835351e-05\n",
            "Prediction: <eos> <eos> <eos>.... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 iter = 100, loss = 4.381743431091309, lr = 1.3587911821036006e-05\n",
            "Prediction: <eos> <eos> '.... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55 iter = 100, loss = 4.328509330749512, lr = 1.3834964763236661e-05\n",
            "Prediction: <eos> <eos> ''... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56 iter = 100, loss = 4.278448104858398, lr = 1.4082017705437316e-05\n",
            "Prediction: <eos> I I.... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57 iter = 100, loss = 4.230011463165283, lr = 1.432907064763797e-05\n",
            "Prediction: <eos> I ''... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58 iter = 100, loss = 4.180129528045654, lr = 1.4576123589838624e-05\n",
            "Prediction: I I ''... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 iter = 100, loss = 4.133031368255615, lr = 1.4823176532039278e-05\n",
            "Prediction: I I I you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60 iter = 100, loss = 4.0855255126953125, lr = 1.5070229474239933e-05\n",
            "Prediction: I I 'you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61 iter = 100, loss = 4.040093421936035, lr = 1.5317282416440588e-05\n",
            "Prediction: I I I you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62 iter = 100, loss = 3.9943957328796387, lr = 1.5564335358641243e-05\n",
            "Prediction: I I I you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63 iter = 100, loss = 3.9503467082977295, lr = 1.5811388300841898e-05\n",
            "Prediction: I I I you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 iter = 100, loss = 3.907180070877075, lr = 1.6058441243042552e-05\n",
            "Prediction: I I I you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 iter = 100, loss = 3.864348888397217, lr = 1.6305494185243207e-05\n",
            "Prediction: I I you you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66 iter = 100, loss = 3.8198864459991455, lr = 1.6552547127443862e-05\n",
            "Prediction: I I I you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67 iter = 100, loss = 3.777959108352661, lr = 1.6799600069644517e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68 iter = 100, loss = 3.735535144805908, lr = 1.7046653011845172e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69 iter = 100, loss = 3.693073272705078, lr = 1.7293705954045827e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70 iter = 100, loss = 3.6539952754974365, lr = 1.754075889624648e-05\n",
            "Prediction: I I you you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 iter = 100, loss = 3.6126482486724854, lr = 1.7787811838447136e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72 iter = 100, loss = 3.5712573528289795, lr = 1.803486478064779e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 iter = 100, loss = 3.5320773124694824, lr = 1.8281917722848446e-05\n",
            "Prediction: I I I you... <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74 iter = 100, loss = 3.4927620887756348, lr = 1.8528970665049097e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75 iter = 100, loss = 3.453685760498047, lr = 1.8776023607249752e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76 iter = 100, loss = 3.4143905639648438, lr = 1.9023076549450407e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77 iter = 100, loss = 3.377269744873047, lr = 1.927012949165106e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78 iter = 100, loss = 3.3400394916534424, lr = 1.9517182433851716e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79 iter = 100, loss = 3.3016984462738037, lr = 1.976423537605237e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80 iter = 100, loss = 3.262112855911255, lr = 2.0011288318253026e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81 iter = 100, loss = 3.2272136211395264, lr = 2.025834126045368e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82 iter = 100, loss = 3.1933064460754395, lr = 2.0505394202654336e-05\n",
            "Prediction: I m a you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83 iter = 100, loss = 3.1595897674560547, lr = 2.075244714485499e-05\n",
            "Prediction: I I you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84 iter = 100, loss = 3.124579906463623, lr = 2.0999500087055645e-05\n",
            "Prediction: I m to you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85 iter = 100, loss = 3.0876402854919434, lr = 2.12465530292563e-05\n",
            "Prediction: I m a you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86 iter = 100, loss = 3.051502227783203, lr = 2.1493605971456955e-05\n",
            "Prediction: I m you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87 iter = 100, loss = 3.018120288848877, lr = 2.174065891365761e-05\n",
            "Prediction: I m you you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88 iter = 100, loss = 2.98427677154541, lr = 2.1987711855858265e-05\n",
            "Prediction: I m you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 iter = 100, loss = 2.950727701187134, lr = 2.223476479805892e-05\n",
            "Prediction: I m you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90 iter = 100, loss = 2.916313648223877, lr = 2.2481817740259574e-05\n",
            "Prediction: I m you you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91 iter = 100, loss = 2.8824706077575684, lr = 2.272887068246023e-05\n",
            "Prediction: I m you you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92 iter = 100, loss = 2.852226495742798, lr = 2.2975923624660884e-05\n",
            "Prediction: I m you you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93 iter = 100, loss = 2.818902015686035, lr = 2.322297656686154e-05\n",
            "Prediction: I m a you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94 iter = 100, loss = 2.7890281677246094, lr = 2.3470029509062193e-05\n",
            "Prediction: I' m go you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95 iter = 100, loss = 2.7568533420562744, lr = 2.3717082451262848e-05\n",
            "Prediction: I' m go you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96 iter = 100, loss = 2.7265191078186035, lr = 2.39641353934635e-05\n",
            "Prediction: I' m you you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97 iter = 100, loss = 2.6932079792022705, lr = 2.4211188335664154e-05\n",
            "Prediction: I m go you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98 iter = 100, loss = 2.6669790744781494, lr = 2.445824127786481e-05\n",
            "Prediction: I' m go you you you. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 iter = 100, loss = 2.637155055999756, lr = 2.4705294220065464e-05\n",
            "Prediction: I m go you you.. <eos> <eos>\n",
            "True: I' m letting you go. <eos> <pad>\n"
          ]
        }
      ],
      "source": [
        "train_model(EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiFNmXLfoHgr"
      },
      "source": [
        "# Beam search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "clFQnJZJoHgr"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def init_vars(sentence, model, K):\n",
        "    src_mask = (sentence != PAD_ID)\n",
        "    e_output = model.encoder(sentence, src_mask)\n",
        "            \n",
        "    out = model.out(torch.LongTensor([[BOUND_ID]]).to(DEVICE), \n",
        "                    e_output, src_mask, \n",
        "                    nopeak_mask(1))\n",
        "    out = F.softmax(out, -1)\n",
        "    \n",
        "    probs, ix = out[:, -1].data.topk(K)\n",
        "    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0).to(DEVICE)\n",
        "    \n",
        "    outputs = torch.zeros(K, MAX_SEQ_LEN).long().to(DEVICE)\n",
        "    outputs[:, 0] = BOUND_ID\n",
        "    outputs[:, 1] = ix[0]\n",
        "    \n",
        "    e_outputs = torch.zeros(K, e_output.size(-2),e_output.size(-1)).to(DEVICE)\n",
        "    e_outputs[:, :] = e_output[0]\n",
        "    \n",
        "    return outputs, e_outputs, log_scores\n",
        "\n",
        "\n",
        "def k_best_outputs(outputs, out, log_scores, i, k):\n",
        "    probs, ix = out[:, -1].data.topk(k)\n",
        "    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1).to(DEVICE) + log_scores.transpose(0,1)\n",
        "    log_probs = log_probs.to(DEVICE)\n",
        "    \n",
        "    k_probs, k_ix = log_probs.view(-1).topk(k)\n",
        "    \n",
        "    row = k_ix // k\n",
        "    col = k_ix % k\n",
        "\n",
        "    outputs[:, :i] = outputs[row, :i]\n",
        "    outputs[:, i] = ix[row, col]\n",
        "\n",
        "    log_scores = k_probs.unsqueeze(0)\n",
        "    \n",
        "    return outputs, log_scores\n",
        "\n",
        "\n",
        "def beam_search(sentence, model, K = 10):    \n",
        "    outputs, e_outputs, log_scores = init_vars(sentence, model, K)\n",
        "    src_mask = (sentence != PAD_ID).to(DEVICE)\n",
        "    ind = None\n",
        "    for i in range(2, MAX_SEQ_LEN):\n",
        "    \n",
        "        trg_mask = nopeak_mask(i)\n",
        "\n",
        "        out = model.out(outputs[:,:i], e_outputs, src_mask, trg_mask)\n",
        "\n",
        "        out = F.softmax(out, dim=-1)\n",
        "    \n",
        "        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, K)\n",
        "        \n",
        "        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).to(DEVICE)\n",
        "        \n",
        "        ones = (outputs==BOUND_ID).nonzero()\n",
        "        for vec in ones:\n",
        "            i = vec[0]\n",
        "            if sentence_lengths[i] == 0:\n",
        "                sentence_lengths[i] = vec[1]\n",
        "        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n",
        "        if num_finished_sentences == K:\n",
        "            alpha = 0.6\n",
        "            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n",
        "            _, ind = torch.max(log_scores * div, 1)\n",
        "            ind = ind.data[0]\n",
        "            break\n",
        "        \n",
        "    if ind is None:\n",
        "        length = (outputs[0] == BOUND_ID).nonzero()\n",
        "        if len(length) != 0:\n",
        "            length = length[1]\n",
        "        else:\n",
        "            length = 10\n",
        "        res = outputs[0][1:length].data.tolist()\n",
        "        return dataset.trg_tokenizer.decode(res)\n",
        "    else:\n",
        "        length = (outputs[ind] == BOUND_ID).nonzero()[1]\n",
        "        res = outputs[ind][1:length].data.tolist()\n",
        "        return dataset.trg_tokenizer.decode(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3zSxH5-oHgr"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqW_PlwVoHgs",
        "outputId": "5634b7bf-b0e1-4be8-8722-f8cbd4d7dcfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (embed): Embedding(43807, 256, padding_idx=1)\n",
              "    (pe): PositionalEncoder()\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): MultiHeadAttention(\n",
              "          (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (out): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (linear_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (linear_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embed): Embedding(43771, 256, padding_idx=1)\n",
              "    (pe): PositionalEncoder()\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm_3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn_1): MultiHeadAttention(\n",
              "          (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (out): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (attn_2): MultiHeadAttention(\n",
              "          (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (out): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (linear_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (linear_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2vywzt9woHgs"
      },
      "outputs": [],
      "source": [
        "def translate(sent):\n",
        "    sent = torch.LongTensor([dataset.src_line_mapper(sent)]).to(DEVICE)\n",
        "    return beam_search(sent, model, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OuqnUoUnoHgs",
        "outputId": "41521567-e9f1-46a7-950d-cbffd5627506"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I I I I I I like like like like like like books.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "translate('j adore les fleurs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdX6Vas_uRVl"
      },
      "source": [
        "Transformer model is trickier to tune than LSTM...\n",
        "\n",
        "3 bonus points to the first three students who tune this notebook to make Transformer correctly translate most of training set in under 30 min training in Colab. Send me the colab link in telegram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NPCtl6aoHgt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}